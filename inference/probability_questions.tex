\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{dsfont}
\usepackage[left=3cm,top=3cm,right=3cm]{geometry}

\newcommand{\xx}{\mathbf{x}}	% The unknown parameters
\newcommand{\data}{\mathbf{D}}  % The data
\newcommand{\dx}{d^N\mathbf{x}} % Volume element in parameter space
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\parindent=0cm

\title{Questions and Exercises\\
for Astro Hack Week 2015}
\author{Brendon J. Brewer}

\begin{document}
\maketitle

\section{Bayesian Inference}


\subsection{Probability theory}
Here are some equations of probability theory. Which rules are being used in
each? Is each equation completely general, or has something specific been
assumed (e.g. independence, mutual exclusivity)?

\begin{eqnarray}
P(A, B | C) &=& P(A | C) P (B | C)\\
P(A \vee B | C) &=& P(A | C) + P(B | C)\\
P(A, B | C, D) &=& P(A, B | D)P(C | A, B, D)/P(C | D)\\
P(Z | I) &=& \sum_i P(A_i | I)P(Z | A_i, I)
\end{eqnarray}

For an interesting physicsy way of getting the hang of writing correct
probability expressions, see arxiv: 1205.4446 by Hogg. Be aware that his
arguments about units apply to probability density functions, whereas
our probabilities above are all dimensionless. Nevertheless, both satisfy rules
of very similar form.


\subsection{Discrete parameter estimation}
You are a customs agent. Among other things, you are supposed to prevent
drugs being smuggled in packages sent into the country. A colleague finds a
package containing two toys. Let the number of toys containing drugs be
$\eta$. Clearly the value of $\eta$ is either 0, 1, or 2. You drill into
one of the toys and find that it does not have drugs (call this proposition
$D$ for data).
Calculate the posterior distribution for $\eta$ given that the tested
toy did not contain drugs. Assume a (discrete) uniform prior, i.e.
$P(\eta=0) = P(\eta=1) = P(\eta=2) = 1/3$.

{\tiny Hint: Use Bayes' rule three times, in the form
$P(\eta = i | D) = \frac{P(\eta=i)P(D|\eta=i)}{P(D)}$, where the denominator is
the same each time.}

\subsection{Continuous parameter estimation}
An X-ray source emits photons at a steady rate, but since it's so distant, we
only pick up a few photons per second.
A standard probabilistic model for the arrival times of the photons is the
``Poisson process''. A specific prediction of this model is that, if the
expected number of photons in a time interval
is $\mu$, the (discrete) probability distribution for the actual number of photons $x$ in that interval is a Poisson distribution:
\begin{eqnarray}
p(x | \mu) &=& \frac{\mu^x e^{-\mu}}{x!}
\end{eqnarray}
Find and plot the posterior distribution for $\mu$ given $x=5$. Use an improper
log-uniform prior proportional to $\mu^{-1}$.

\subsection{Prediction}
Use the posterior distribution obtained in the previous question to calculate
the predictive distribution for $x'$, the number of photons observed in a
different one second interval, given $x=5$. Plot the predictive distribution
and compare it with what you'd get by naively assuming the best fit
(maximum likelihood) value $\mu=5$ to make the prediction.\\

{\bf Hint 1: }Write down the probability distribution for $x'$ given
$\mu$ and $x$, and then marginalise out $\mu$.\\

{\bf Hint 2: }You may need to do some numerical integration.

\end{document}

