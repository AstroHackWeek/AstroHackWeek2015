{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function,division\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "import os,time\n",
    "\n",
    "import theano\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import adagrad\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.cross_validation import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nt1=time.time()\\nrt='/home/michelle/Dropbox/Project/DES_images/data/'\\nX_train=np.load(rt+'X_train.npy')\\nX_val=np.load(rt+'X_val.npy')\\nX_test=np.load(rt+'X_test.npy')\\n\\nY_train=np.load(rt+'Y_train.npy')\\nY_val=np.load(rt+'Y_val.npy')\\nY_test=np.load(rt+'Y_test.npy')\\nprint('Read data in ',time.time()-t1,'s')\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "t1=time.time()\n",
    "rt='/home/michelle/Dropbox/Project/DES_images/data/'\n",
    "X_train=np.load(rt+'X_train.npy')\n",
    "X_val=np.load(rt+'X_val.npy')\n",
    "X_test=np.load(rt+'X_test.npy')\n",
    "\n",
    "Y_train=np.load(rt+'Y_train.npy')\n",
    "Y_val=np.load(rt+'Y_val.npy')\n",
    "Y_test=np.load(rt+'Y_test.npy')\n",
    "print('Read data in ',time.time()-t1,'s')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes 12\n",
      "Read data in  0.0989861488342 s\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "rt='/home/michelle/Dropbox/Project/DES_images/data/'\n",
    "X=np.load(rt+'SVA1_multiclass_images.npy')\n",
    "Y=np.load(rt+'SVA1_multiclass_classes.npy')\n",
    "\n",
    "nb_classes = len(np.unique(Y))\n",
    "print('Number of classes',nb_classes)\n",
    "\n",
    "ss = ShuffleSplit(len(Y), n_iter=1,test_size=0.4)\n",
    "mylist = list(ss)\n",
    "train, test = mylist[0]\n",
    "\n",
    "#I actually want to split the \"test\" into validation and test\n",
    "val=test[:(int)(0.75*len(test))]\n",
    "test=test[(int)(0.75*len(test)):]\n",
    "\n",
    "X_train=X[train]\n",
    "Y_train=Y[train]\n",
    "X_val=X[val]\n",
    "Y_val=Y[val]\n",
    "X_test=X[test]\n",
    "Y_test=Y[test]\n",
    "\n",
    "print('Read data in ',time.time()-t1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZKK+n/hWH0puJBL6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d912ca550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check the training set is representative\n",
    "plt.hist(Y_train,nb_classes,facecolor='none',edgecolor='b');\n",
    "plt.hist(Y_val,nb_classes,facecolor='none',edgecolor='g');\n",
    "plt.hist(Y_test,nb_classes,facecolor='none',edgecolor='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(Y_val, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train=X_train[:,:,:50,:]\n",
    "#X_val=X_val[:,:,:50,:]\n",
    "#X_test=X_test[:,:,:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 102\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50 \n",
    "nb_epoch = 20\n",
    "\n",
    "# shape of the image (SHAPE x SHAPE)\n",
    "shapex, shapey = X_train[0].shape[-2],X_train[0].shape[-1]\n",
    "#print(X_train.shape)\n",
    "print(shapex,shapey)\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32 #32\n",
    "# level of pooling to perform (POOL x POOL)\n",
    "nb_pool = 2\n",
    "# level of convolution to perform (CONV x CONV)\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(X_train[1][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, 1, nb_conv, nb_conv, border_mode='full'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_filters, nb_conv, nb_conv))\n",
    "convout1=Activation('relu')\n",
    "model.add(convout1)\n",
    "model.add(MaxPooling2D(poolsize=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Convolution2D(nb_filters,nb_filters, nb_conv, nb_conv, border_mode='full'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_filters, nb_conv, nb_conv))\n",
    "convout2=Activation('relu')\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D(poolsize=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "model.add(Flatten())\n",
    "# the resulting image after conv and pooling is the original shape\n",
    "# divided by the pooling with a number of filters for each \"pixel\"\n",
    "# (the number of filters is determined by the last Conv2D)\n",
    "model.add(Dense(nb_filters * (shapex // nb_pool//nb_pool) * (shapey // nb_pool//nb_pool), 128))\n",
    "#model.add(Dense(nb_filters * (shapex // nb_pool) * (shapey // nb_pool), 128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Gilles suggested adding an extra set of layers here to improve accuracy\n",
    "model.add(Dense(128, 128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "#ad=adagrad(clipnorm=1)\n",
    "#model.compile(loss='mean_squared_error', optimizer=ad)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=ad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.get_config()\n",
    "fname='model.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1290 samples, validate on 645 samples\n",
      "Epoch 0\n",
      "  50/1290 [>.............................] - ETA: 211s - loss: 14.0099 - acc: 0.0400"
     ]
    }
   ],
   "source": [
    "checkpointer=ModelCheckpoint(fname, verbose=0, save_best_only=True)\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1, validation_data=(X_val, Y_val),callbacks=[checkpointer])\n",
    "score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model=Sequential()\n",
    "#model.load_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_fit=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_fit=y_fit.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_test=np.load(rt+'Y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(Y_test==y_fit)/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def nice_imshow(ax, data, vmin=None, vmax=None, cmap=None):\n",
    "    \"\"\"Wrapper around pl.imshow\"\"\"\n",
    "    if cmap is None:\n",
    "        cmap = cm.jet\n",
    "    if vmin is None:\n",
    "        vmin = data.min()\n",
    "    if vmax is None:\n",
    "        vmax = data.max()\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    im = ax.imshow(data, vmin=vmin, vmax=vmax, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar(im, cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "def make_mosaic(imgs, nrows, ncols, border=1):\n",
    "    \"\"\"\n",
    "    Given a set of images with all the same shape, makes a\n",
    "    mosaic with nrows and ncols\n",
    "    \"\"\"\n",
    "    nimgs = imgs.shape[0]\n",
    "    imshape = imgs.shape[1:]\n",
    "    \n",
    "    mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
    "                            ncols * imshape[1] + (ncols - 1) * border),\n",
    "                            dtype=np.float32)\n",
    "    \n",
    "    paddedh = imshape[0] + border\n",
    "    paddedw = imshape[1] + border\n",
    "    for i in xrange(nimgs):\n",
    "        row = int(np.floor(i / ncols))\n",
    "        col = i % ncols\n",
    "        \n",
    "        mosaic[row * paddedh:row * paddedh + imshape[0],\n",
    "               col * paddedw:col * paddedw + imshape[1]] = imgs[i]\n",
    "    return mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convout1_f = theano.function([model.get_input(train=False)], convout1.get_output(train=False))\n",
    "#convout2_f = theano.function([model.get_input(train=False)], convout2.get_output(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind=10\n",
    "plt.imshow(X_test[ind][0],cmap='gray')\n",
    "plt.title(Y_test[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C1 = convout1_f(X_test[ind:ind+1])\n",
    "C1 = np.squeeze(C1)\n",
    "print(\"C1 shape : \", C1.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "#plt.suptitle('convout1')\n",
    "nice_imshow(plt.gca(), make_mosaic(C1, 6, 6,border=1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C2 = convout2_f(X_test[ind:ind+1])\n",
    "C2 = np.squeeze(C2)\n",
    "print(\"C2 shape : \", C2.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "#plt.suptitle('convout1')\n",
    "nice_imshow(plt.gca(), make_mosaic(C2, 6, 6,border=1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
